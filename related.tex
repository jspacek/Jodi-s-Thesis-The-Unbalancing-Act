%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = diss.tex

\chapter{Related Work} 
\label{sec:related}

%\todo{https://code.briarproject.org/briar/tor-circumvention-analytics/}
%\todo{Enemy at the Gateways}
%\todo{Proxy recycling (unpublished)}

Censorship resistance systems \ac{CRS} are composed of two parts; 1) communication establishment, or handshake, needed to join the \ac{CRS}, and 2) the conversation stage where the actual information is exchanged between the client and the censored site. In \textit{SOK: Making sense of censorship resistance systems} \cite{khattak2016sok}, categorizations of different types of \ac{CRS} are outlined based on the system's approach to these two functions. 

There are two main approaches to communication establishment in censorship resistance systems; resource scheduling and allocation approach, and the trust-based approach. Resource scheduling and allocation fight a losing battle to distribute proxies under a censorship threat model where proxies are continuously blocked. Proxies need to be birthed or placed into reserve in order to keep up with the censor's blocking rate. The advantage of these schemes is that they are lightweight and easy to implement.

The goal of trust-based proxy distribution is to mitigate blocking by building trust between honest users of the system and the proxy distributor. They achieve this by distinguishing honest clients from malicious clients. We outline systems and techniques that fall under a similar censorship threat model as our own, where the censor is omnipotent and blocks proxies based on information gained by posing as an honest user.

Note that other types of anonymous systems, such as Vuvuzela \cite{vandenHooff:2015:VSP:2815400.2815417}, Dissent \cite{corrigan2010dissent}, and Freenet \cite{clarke2001freenet}, are concerned with maintaining levels of anonymity in order to prevent an adversary from learning about messages from a sender to a receiver. The highest level of anonymity in these systems is a \textit{third axis} where one cannot tell that a user is communicating with any other user \cite{reiter1999anonymous}. The adversary in the proxy distribution problem under a censorship threat model is vastly stronger than in general anonymity systems. The goal of \ac{CRS} is to obfuscate evidence that a user is in the system at all, as well as to hide the activity of the user within said system.

\section{Resource Scheduling and Allocation}

\textbf{Tor's Bridge Distribution.} Tor bridges are private relays or proxies used for censorship circumvention. Tor bridge \ac{IP} addresses and fingerprints are distributed out of band using registered email or through a captcha site on the Tor blog. Tor's BridgeDB authority distributes up to 3 new bridge IPs and corresponding fingerprints to clients based on a hashring uniform distribution. Bridge requests are rate limited by a centralized bridge distributor. Despite these efforts, censors in China have discovered and blocked most of the bridges given through the public distribution channels. Bridge enumeration attacks are possible using bulk emails via \ac{HTTPS} \cite{ling2015tor}. Tor uses a fingerprint as a shared secret scheme to thwart active probing, however this can't prevent bridge discovery using a delayed insider attack \cite{fifield2016censors}. \\

\textbf{TorBricks.} The TorBricks \cite{zamani2017torbricks} design distributes proxies in groups to guarantee a maximum number of rounds until all honest users can connect to a proxy server after some number of retries. It relies on exponential growth in the number of proxies in order to provide these guarantees of a logarithmic number of rounds. A caveat in this system is, if there are no unblocked proxies in the current group, then the algorithm requires that a unique bridge be allocated per each user. 

While this approach allows for adaptive adjustment to a proportion of attackers in the system, it requires a great deal of resources. For example, if a \ac{CRS} had enough proxies to give one out per each user, we would not have the problem of proxy distribution since we could hand out private proxies. If we have private proxies, then no attacker could discover an honest user's proxy because users would not have to share.\\

\textbf{Fighting Censorship with Algorithms.}
Mahdian \cite{mahdian2010fighting} studies proxy distribution as an algorithmic problem and gives bounds on the number of proxies required to provide service to clients, some of whom are adversaries. He includes a theoretical analysis of bounds for the number of proxies needed to survive an insider attack. His theorems use k-union-free families of sets, probabilistic methods, and extremal set theory to give lower and upper bounds. 

Mahdian's scheme creates two sets of users, trusted and suspicious, and distributes keys based on the user's membership in one of these two sets. Users are divided into these sets based on their association with compromised keys; they are moved from the trusted group to the suspicious group. Fresh keys are only handed out to trusted users. This adaptive model bounds the number of keys that an adversary can compromise thus providing guarantees for the user with respect to the expected total number of keys required to give every legitimate user access.

In Mahdian's model, a key represents a servlet or proxy server. His scheme assumes a known number of malicious users and there are no bounds on the number of clients a proxy can serve. While maintenance of keys is usually relatively simple in practice, the logistics of proxy server maintenance is more involved. It is an impractical assumption that keys (representing proxies) can be distributed to an unlimited number of users without significant overhead. 

Mahdian's algorithm distributes an increasing number of keys to users in order to reduce the risk posed by a growing number of adversaries. This does not address the case where adversaries are controlled by the same entity, such as a censor. For example, it does not take into consideration the enumeration attack. This attack is further exacerbated by the reuse of keys, as opposed to the removal of suspect keys.\\


\section{Trust-based Allocation}

%\todo{HYPHAE: Social Secret Sharing https://patternsinthevoid.net/hyphae/hyphae.pdf}

\textbf{Proximax.} The main goal of the Proximax \cite{mccoy2011proximax} reputation-based system is to maximize the yield of a proxy resource, where yield is the number of user-hours per day before a proxy is blocked, calculated as the product of usage and lifetime. Each proxy resource is advertised on multiple channels. This novel use of a channel relies on a fast flux technique that piggybacks on \ac{DNS} infrastructure. Proximax registers multiple proxies to the same domain name and load balances them based on their current utilization and resource risk parameter. 

The usage and risk of a proxy resource is the sum of the risk of each of the channels where it is distributed. Resource risk is calculated as a maximum likelihood estimate of blocking - it is only an approximation because resources are advertised on multiple channels, and the risk per channel cannot be sampled directly. In other words, when a proxy is blocked, there is no way to detect the specific channel that caused the block and so it is difficult to tease out channel from proxy risk. 

All proxies will eventually be discovered in proxy distribution, so Proximax adds a trust scheme to delay censor discovery. Registered users build up their reputation score and invite new users, handled by a registration system. The registration system allocates proxies that have higher risk to lower reputation scores. They widely disseminate the location of low risk proxies in order to maximize their yield. This leads to the potential of rapid enumeration attacks, where the best proxies are enumerated in quick succession. 

Proximax's trust scheme is likely to be thwarted by colluding insider attackers where registered users build up reputation to invite other users, as it does not work well in a delayed blocking attack. Furthermore, the risk approximation may not be particularly useful because if there is only a single attacker assigned to a proxy, and with the reasonable assumption that all attackers are controlled by the same censor entity, then this proxy has the same likelihood of being blocked as a proxy to which several insider attackers are assigned. \\

\textbf{rBridge.} rBridge \cite{wang2013rbridge} is a trust-based reputation system for a Tor bridge distributor that addresses insider attacks, minimizes user wait time for an available proxy, and preserves privacy of client assignment information. The rBridge distributor computes user reputation based on the uptime of bridges to which a user is assigned. A payment system allows users to buy unblocked bridges to prevent repeated blocks. They show rBridge's user-hours served is at least one order of magnitude more than Proximax and that thirsty hours of users waiting for a proxy is minimized. This is mainly achieved by making sure that the overall rate of new bridges outpaces the rate of proxy blocks, and by reserving half of their bridge resources for future invitations.

A significant contribution of rBridge's design is their privacy preserving scheme using anonymous credentials to build trust, invite users, and obtain signed credentials. Restricting proxy assignments can lead to user fingerprinting as there are unique combinations of proxies tied to a single user. Previous work in pseudonymous credentials and oblivious transfer methods don't work well in proxy systems because an attacker can still infer client assignments based on behaviour after a proxy is blocked. rBridge hides bridge assignment from even the distributor by enabling the proxy assignments to be written and updated by users. They take extra measures to maintain integrity using anonymous credentials, one-time tokens and secrets that cannot be forged owing to zero knowledge proofs and blind signatures. 

In addressing the delayed blocking attack, they note that invitation tickets are randomly distributed over all users, so there is a chance that the corrupt user may not receive a ticket. Since tickets cannot be transferred, it is no more likely that an attacker receives a ticket than an honest user. However, they do not provide analysis given that even just one corrupt user is more than enough to block a proxy, therefore an assignment of a proxy to a single attacker is more significant than assignment to an honest user. \\


\section{Routing}

Routing users through decoy paths as a mechanism to discover proxies is a vastly different approach to the proxy distribution problem and handshake used in censorship resistance systems. Essentially, this approach solves the issue of censors posing as honest users and blocking proxies because censors do not want to block the decoy paths. This is because there would be too much collateral damage as the decoy paths are heavily used and it is difficult to tell if users are accessing blocked sites from the decoys. The barrier to implement these solutions, however, is that they require a large commitment from either \ac{CDN} or \ac{ISP} to build the decoy paths and to maintain the network that provides the anonymous handshake.\\

\textbf{Telex.} This \ac{CRS} uses destination obfuscation via decoy routing at Telex stations that are \textit{end-to-middle} proxies located in their own network infrastructure \cite{wustrow2011telex}. Sessions between users and Telex have special tags to direct them through to censored sites. These proxies are built into the network with involvement from local \ac{ISP} that must deploy Telex stations on paths between networks under censor control and blocked destinations.\\

\textbf{Domain Fronting.} An elegant way to circumvent censors is through domain fronting, where a user is routed through a legitimate intermediary, such as a \ac{CDN} \cite{Fifield2017a}. These intermediaries are used to rendezvous with Tor and cannot be detected by a censor because the \ac{CDN}'s network is beyond the censor boundary. Domain fronting is the most reliable way to perform the rendezvous handshake and recently it is the only protocol that works in China \cite{TORDOMAIN:2019}. However, we see that major \ac{CDN} like Google and Amazon no longer support domain fronting. Microsoft's Azure cloud is a temporary fix as there is no formal agreement between Microsoft and Tor to support domain fronting in the future.\\

\section{Related Approaches}

The following works aren't directly related to the problem of censorship circumvention. However, their analysis of resource allocation is closely tied to the coupon collector analysis in this thesis. Their lightweight distribution under a different threat model also relates to and inspired our approach.\\

\textbf{Coupon Collector and Power of d Choices.} The Power of d Choices was analyzed for the generalized form of the coupon collector problem in \cite{xu2011generalized}. This includes the case where a collector wants to collect $m$ out of $n$ total coupons. The collector selects $d$ coupons out of the total collection and chooses the least heavily loaded (or least collected) coupon in each draw. This benefits the collector because duplicate coupons are discarded. They show that the expected number of draws to collect $m$ out of a total of $n$ coupons is $(n \log{n})/d + (n/d )(m âˆ’ 1) \log{\log{n}} + O (mn)$. Although this is opposite from our reverse power of 2 choice algorithm, and far more complex in its analyses, it is a useful counterpoint to our goal of delaying enumeration, as the goal here is to enable the coupon collector to collect coupons as quickly as possible.\\

\textbf{Proxisch.} Proxisch \cite{jiang2016proxisch} is an application of a scheduling algorithm for proxy distribution in web crawling applications. Although Proxisch is intended for distributed web crawling, the proxy server selection mechanism has a similar goal shared by the proxy distribution problem; to reduce the risk of assigning high risk proxies to clients. This work estimates the reliability of proxies based on a reliability calculation and uses queuing theory to organize proxies by their respective reliability factors. 

To model the life of a proxy, they use an exponential distribution based on the life of an ideal lamp. They show in their simulations that the actual life span of some proxy servers is close to the exponential distribution. This leads to the calculation of an optimal update period for cycling proxies among processes. They compare their result to a polling scheduling solution that illustrates higher successful service rates within shorter time periods for their solution. Their resource scheduling algorithm approach is similar to a randomized proxy selection based on attributes of proxies, such as time, reputation, or credits because it orders proxies based on criterion. This is a move away from more complex, monolithic designs favouring proxies that earn standing over time within the system. 

It's not possible to directly translate this solution into the problem addressed in this thesis, since modeling the lifetime of a proxy server does not directly translate to the motivations of a powerful censor that can cut the lifetime of a proxy at any time. However, this work does provide useful hints for how one may approach a lightweight proxy distribution design.\\


